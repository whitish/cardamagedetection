{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24487909-94be-4287-82c6-456b140b1b7f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Convert data into coco format\n",
    "Official data set page: https://humansintheloop.org/resources/datasets/car-parts-and-car-damages-dataset/\n",
    "\n",
    "The original data contains the next classes to annotate all damage types:\n",
    "```\n",
    "classes = ['Cracked', 'Scratch', 'Flaking', 'Broken part', 'Corrosion', 'Dent','Paint chip','Missing part']\n",
    "```\n",
    "For the purpose of this pre-processing, we will be using only one class to identify damages -  for binary annotations (damage / no damage):\n",
    "```\n",
    "classes = ['damage']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4125c3a-dc68-4a9c-9622-de1c87ebd0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = \"data/humansintheloop/Carpartsdataset/File1/\"\n",
    "\n",
    "# sample image\n",
    "_ = \"\"\"\n",
    "image_path = os.path.join(data_dir, \"img/\", \"Car damages 321.png\")\n",
    "json_path = os.path.join(data_dir, \"ann/\", \"Car damages 321.png.json\")\n",
    "\n",
    "# Load annotations from the JSON file\n",
    "with open(json_path, 'r') as f:\n",
    "    annotations_data = json.load(f)\n",
    "\n",
    "# Function to draw annotations on the image\n",
    "def draw_annotations(image, annotations):\n",
    "    for shape in annotations[\"objects\"]:\n",
    "        label = shape[\"classTitle\"]\n",
    "        points = shape[\"points\"][\"exterior\"]\n",
    "        pts = [(int(point[0]), int(point[1])) for point in points]\n",
    "        pts = np.array(pts, np.int32)\n",
    "        pts = pts.reshape((-1, 1, 2))\n",
    "\n",
    "        color = (0, 255, 0)  # Green color for bounding boxes\n",
    "        cv2.polylines(image, [pts], isClosed=True, color=color, thickness=2)\n",
    "        cv2.putText(image, label, (pts[0][0][0], pts[0][0][1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "# load the image\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "print (\"Size of the image:\",image.shape)\n",
    "# display the annotations\n",
    "image_with_annotations = draw_annotations(image, annotations_data)\n",
    "Image.fromarray(image_with_annotations)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361b3a3-c6d7-4c2f-bebb-d2e58d1f39da",
   "metadata": {},
   "source": [
    "# Check the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8d82a680-a409-4f44-88df-7f068eba5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all unique classes and their distribution\n",
    "_ = \"\"\"\n",
    "class_dist = {}\n",
    "file_count = 0\n",
    "json_dir = os.path.join(data_dir, \"ann/\")\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(json_dir, filename)) as f:\n",
    "            annotation_data = json.load(f)\n",
    "            for shape in annotation_data[\"objects\"]:\n",
    "                if shape[\"classTitle\"] in class_dist:\n",
    "                    class_dist[shape[\"classTitle\"]] += 1\n",
    "                else:\n",
    "                    class_dist[shape[\"classTitle\"]] = 1\n",
    "        file_count += 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f877d450-17fe-4d6a-a208-cc13b3080de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"Total annotation-file count:\", file_count)\n",
    "#print (\"Distribution of the classes:\", class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78491b74-54bc-458b-96b7-d9a449ef07a7",
   "metadata": {},
   "source": [
    "# Save the data to COCO JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f4b053-ebb2-4c19-beb2-8643556808e3",
   "metadata": {},
   "source": [
    "Now, lets convert the image and annotation data into COCO JSON format.\n",
    "\n",
    "The COCO (Common Objects in Context) dataset is a widely used dataset for object detection, segmentation, and captioning tasks. The annotations in the COCO dataset are stored in JSON format. Learn more about the COCO dataset.\n",
    "\n",
    "The COCO JSON format is structured and standardized to represent object annotations and metadata for each image in the dataset. Here's an overview of the key components of the COCO JSON format:\n",
    "\n",
    "Image Information:\n",
    "\n",
    "id: A unique identifier for each image.\n",
    "width: Width of the image in pixels.\n",
    "height: Height of the image in pixels.\n",
    "file_name: The filename of the image.\n",
    "Annotation Information:\n",
    "\n",
    "id: A unique identifier for each annotation.\n",
    "image_id: The identifier of the image to which this annotation belongs.\n",
    "category_id: The identifier of the category (class) label for the annotated object.\n",
    "bbox: A list of four values representing the bounding box coordinates of the object. The order is [xmin, ymin, width, height].\n",
    "area: The area of the object bounding box.\n",
    "segmentation: The segmentation mask of the object (used for semantic segmentation tasks).\n",
    "iscrowd: A binary flag (0 or 1) indicating whether the annotated object is a single instance (0) or a group or crowd (1).\n",
    "attributes: Additional attributes associated with the annotation (e.g., color, shape, etc.).\n",
    "Category Information:\n",
    "\n",
    "id: A unique identifier for each category (class) label.\n",
    "name: The name of the category.\n",
    "The JSON file may also include additional information like licenses, dataset information, and annotations for captions (in case of captioning tasks).\n",
    "\n",
    "Here's an example of a simplified JSON representation of a COCO annotation for a single image with one annotated object:\n",
    "```\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"width\": 640,\n",
    "      \"height\": 480,\n",
    "      \"file_name\": \"example.jpg\"\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"image_id\": 1,\n",
    "      \"category_id\": 1,\n",
    "      \"bbox\": [100, 200, 150, 100],\n",
    "      \"area\": 15000,\n",
    "      \"segmentation\": [100, 200, 250, 200, 250, 300, 100, 300],\n",
    "      \"iscrowd\": 0,\n",
    "      \"attributes\": {}\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"name\": \"cat\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "Please note that this is a simplified example, and COCO JSON files may contain annotations for multiple images and objects, as well as additional metadata.\n",
    "\n",
    "For this exercise, only the top 5 classes i.e., 'Scratch', 'Broken part','Dent','Paint chip','Missing part' are used.\n",
    "\n",
    "Note: The label id of the classes will be in the order of the classes specified in the below list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc93dc8-7dc9-4a2a-aecf-1d1ade276028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the classes required\n",
    "#classes = ['Cracked', 'Scratch', 'Flaking', 'Broken part', 'Corrosion', 'Dent','Paint chip','Missing part']  # to annotate all damage types\n",
    "classes = ['damage']  # for binary annotations (damage / no damage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "db60a783-4456-4b1e-aa5a-347f58d80e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "_ = \n",
    "\"\"\"\n",
    "val_d = ['Car damages 1194.png',\n",
    " 'Car damages 602.png',\n",
    " 'Car damages 859.png',\n",
    " 'Car damages 909.png']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f551d1f1-4fda-40a1-892b-efc4730bef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pycocotools.coco import COCO\n",
    "#coco = COCO('../datasets/coco/annotations/instances_train2017.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9626ee9b-55c6-436d-9902-047857c52a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate \"area\" for annotations\n",
    "_ = \"\"\"\n",
    "from pycocotools import mask, coco\n",
    "from pycocotools.mask import frPyObjects, area\n",
    "\n",
    "seg = [\n",
    "    [\n",
    "        379,\n",
    "        216,\n",
    "        337,\n",
    "        218,\n",
    "        300,\n",
    "        223,\n",
    "        318,\n",
    "        238,\n",
    "        350,\n",
    "        237,\n",
    "        369,\n",
    "        231,\n",
    "        375,\n",
    "        227\n",
    "    ]\n",
    "]\n",
    "segmentation = [\n",
    "    [379, 216],\n",
    "    [337, 218],\n",
    "    [300, 223],\n",
    "    [318, 238],\n",
    "    [350, 237],\n",
    "    [369, 231],\n",
    "    [375, 227]\n",
    "]\n",
    "\"\"\"\n",
    "#a = frPyObjects(seg, 1024, 1024)\n",
    "#area(a)\n",
    "\n",
    "\n",
    "#coco.annToRLE()\n",
    "\n",
    "\n",
    "#area = mask.area(segmentation)\n",
    "#print(\"Area:\", area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "64d50b4f-2846-43cc-b57a-588f958e6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from shapely.geometry import Polygon, MultiPolygon # (pip install Shapely)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d5f481-782b-429f-8290-a036583a2fff",
   "metadata": {},
   "source": [
    "Prepare image annotations according to coco format. Store the results in train and val directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4fc170-adad-424c-958a-c791df9ca08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the annotation files and convert the annotations to COCO JSON format.\n",
    "\n",
    "# Fraction of images for training/validation: 80/20\n",
    "train_frac = 0.8  # debug: 1-0.005\n",
    "\n",
    "# Replace these paths with your dataset paths\n",
    "json_dir = os.path.join(data_dir, \"ann/\")\n",
    "#coco_path_damage = f\"{data_dir}/coco_annotations_damage.json\"    # damage / no damage\n",
    "#coco_path_damages = f\"{data_dir}/coco_annotations_damages.json\"  # damage type\n",
    "\n",
    "# Initialize lists to store annotations and images data\n",
    "annotations_list_train = []\n",
    "annotations_list_val = []\n",
    "images_list_train = []\n",
    "images_list_val = []\n",
    "\n",
    "# Create a dictionary to map class names to class IDs\n",
    "\n",
    "_ =\"\"\"\n",
    "class_names = {}\n",
    "for i in range(len(classes)):\n",
    "    class_names[classes[i]] = i\n",
    "print (class_names)\n",
    "\"\"\"\n",
    "\n",
    "# create a dict with class ids\n",
    "class_to_label = {class_name: i for i, class_name in enumerate(classes)}\n",
    "\n",
    "\n",
    "# convert polygon annotations to COCO-style bounding boxes\n",
    "def polygon_to_box(polygon) -> list:\n",
    "    \"\"\"Convert 1 polygon into a bounding box.\n",
    "\n",
    "    # Arguments\n",
    "      polygon: a numpy array of shape (N, 2) representing N vertices\n",
    "               of the hand segmentation label (polygon); each vertex\n",
    "               is a point: (x, y)\n",
    "    \"\"\"\n",
    "    if len(polygon) < 3:  # a polygon has at least 3 vertices\n",
    "        return None\n",
    "    x_min = np.min(polygon[:, 0])\n",
    "    x_max = np.max(polygon[:, 0])\n",
    "    y_min = np.min(polygon[:, 1])\n",
    "    y_max = np.max(polygon[:, 1])\n",
    "    H = y_max - y_min\n",
    "    W = x_max - x_min\n",
    "    return [x_min, y_min, W, H]\n",
    "\n",
    "# Iterate through the JSON annotation files\n",
    "for idx, filename in enumerate(os.listdir(json_dir)):\n",
    "    if filename.endswith(\".json\"):\n",
    "        is_train = np.random.choice([0,1], size=1, p=[1-train_frac, train_frac])[0]  # use image for training\n",
    "        #is_train = filename.replace(\".json\", \"\") not in val_d\n",
    "        \n",
    "        with open(os.path.join(json_dir, filename)) as f:\n",
    "            ann_data = json.load(f)\n",
    "            image_filename = filename.replace(\".json\", \"\")\n",
    "            image_path = os.path.join(data_dir, \"img\", image_filename)\n",
    "            image = {\n",
    "                \"file_name\": image_filename,\n",
    "                \"height\": ann_data[\"size\"][\"height\"],\n",
    "                \"width\": ann_data[\"size\"][\"width\"]\n",
    "                }\n",
    "            if is_train:\n",
    "                train_image_id = len(images_list_train)\n",
    "                #print(f\"[train] image_id: {train_image_id}\")\n",
    "                image[\"id\"] = train_image_id# + 1\n",
    "                images_list_train.append(image)\n",
    "            else:\n",
    "                val_image_id = len(images_list_val)\n",
    "                #print(f\"[val] image_id: {val_image_id}\")\n",
    "                image[\"id\"] = val_image_id# + 1\n",
    "                images_list_val.append(image)\n",
    "                \n",
    "            for o in ann_data[\"objects\"]:\n",
    "                label = o[\"classTitle\"]\n",
    "                label = \"damage\"  # overwrite class - for binary annotation (damage / no damage)\n",
    "                # only use the classes selected\n",
    "                if label in classes:\n",
    "                    pass\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                class_id = class_to_label[label]  # Use class_ids\n",
    "                bbox = polygon_to_box(np.array(o[\"points\"][\"exterior\"]))\n",
    "                #print(\"here\")\n",
    "                annotation = {\n",
    "                    \"category_id\": class_id+1,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"bbox\": bbox,\n",
    "                    #\"bbox_mode\": BoxMode.XYWH_ABS, #BoxMode.XYXY_ABS,\n",
    "                    #\"segmentation\": [o[\"points\"][\"exterior\"]],\n",
    "                    \"segmentation\": [np.array(o[\"points\"][\"exterior\"]).ravel().tolist()]\n",
    "                }\n",
    "                \n",
    "                if is_train:\n",
    "                    annotation.update(\n",
    "                        {\n",
    "                        \"id\": len(annotations_list_train),#+ 1,\n",
    "                        \"image_id\": train_image_id,\n",
    "                        })\n",
    "                    annotations_list_train.append(annotation)\n",
    "                else:\n",
    "                    annotation.update(\n",
    "                        {\n",
    "                        \"id\": len(annotations_list_val), # + 1,\n",
    "                        \"image_id\": val_image_id,\n",
    "                        })\n",
    "                    annotations_list_val.append(annotation)\n",
    "\n",
    "# Create the COCO data dictionary\n",
    "coco_data_train = {\n",
    "    \"annotations\": annotations_list_train,\n",
    "    \"images\": images_list_train,\n",
    "    \"categories\": [{\"id\": class_id+1, \"name\": class_name} for class_name, class_id in class_to_label.items()]\n",
    "}\n",
    "coco_data_val = {\n",
    "    \"annotations\": annotations_list_val,\n",
    "    \"images\": images_list_val,\n",
    "    \"categories\": [{\"id\": class_id+1, \"name\": class_name} for class_name, class_id in class_to_label.items()]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a991417-662e-4a8b-b903-9bf7d943ec03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': {'category_id': 1,\n",
       "  'iscrowd': 0,\n",
       "  'bbox': [266.0, 127.0, 338.0, 112.0],\n",
       "  'segmentation': [[266.0,\n",
       "    150.0,\n",
       "    281.0,\n",
       "    174.0,\n",
       "    332.0,\n",
       "    184.0,\n",
       "    394.0,\n",
       "    200.0,\n",
       "    433.0,\n",
       "    221.0,\n",
       "    464.0,\n",
       "    239.0,\n",
       "    481.0,\n",
       "    236.0,\n",
       "    485.0,\n",
       "    230.0,\n",
       "    529.0,\n",
       "    223.0,\n",
       "    555.0,\n",
       "    216.0,\n",
       "    584.0,\n",
       "    208.0,\n",
       "    604.0,\n",
       "    201.0,\n",
       "    600.0,\n",
       "    189.0,\n",
       "    590.0,\n",
       "    174.0,\n",
       "    576.0,\n",
       "    166.0,\n",
       "    550.0,\n",
       "    154.0,\n",
       "    526.0,\n",
       "    146.0,\n",
       "    503.0,\n",
       "    138.0,\n",
       "    482.0,\n",
       "    131.0,\n",
       "    472.0,\n",
       "    127.0,\n",
       "    470.0,\n",
       "    129.0,\n",
       "    447.0,\n",
       "    134.0,\n",
       "    406.0,\n",
       "    134.0,\n",
       "    354.0,\n",
       "    136.0,\n",
       "    307.0,\n",
       "    142.0]],\n",
       "  'id': 0,\n",
       "  'image_id': 0},\n",
       " 'images': {'file_name': 'Car damages 101.png',\n",
       "  'height': 440,\n",
       "  'width': 637,\n",
       "  'id': 0},\n",
       " 'categories': [{'id': 1, 'name': 'damage'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show sample annotation\n",
    "{'annotations': coco_data_train['annotations'][0],\n",
    " 'images': coco_data_train['images'][0],\n",
    " 'categories': coco_data_train['categories']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e25819aa-e6c2-4632-bfdd-714fbf46beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class: damage types\n",
    "# Save the COCO data to a JSON file\n",
    "_ = \"\"\"\n",
    "coco_path_damages_train = f\"{data_dir}train/coco_annotations_damages.json\"  # damage type\n",
    "\n",
    "coco_path_damages_val = f\"{data_dir}val/coco_annotations_damages.json\"  # damage type\n",
    "\n",
    "# train annotations\n",
    "with open(coco_path_damages_train, \"w\") as f:\n",
    "    json.dump(coco_data_train, f, indent=4)\n",
    "\n",
    "\n",
    "# val annotations\n",
    "with open(coco_path_damages_val, \"w\") as f:\n",
    "    json.dump(coco_data_val, f, indent=4)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "82fb6550-0536-4371-be54-4c7381a2c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single class: damage / no damage\n",
    "# Save the COCO data to a JSON file\n",
    "coco_path_damage_train = f\"{data_dir}train/coco_annotations_damage.json\"    # damage / no damage\n",
    "\n",
    "coco_path_damage_val = f\"{data_dir}val/coco_annotations_damage.json\"    # damage / no damage\n",
    "\n",
    "\n",
    "# train annotations\n",
    "with open(coco_path_damage_train, \"w\") as f:\n",
    "    json.dump(coco_data_train, f, indent=4)\n",
    "\n",
    "\n",
    "# val annotations\n",
    "with open(coco_path_damage_val, \"w\") as f:\n",
    "    json.dump(coco_data_val, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a1afcdf4-620b-447e-bf23-3b01dce15a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images to train and val paths\n",
    "import shutil\n",
    "# Train\n",
    "_ = \n",
    "\"\"\"\n",
    "with open(coco_path_damage_train, \"r\") as file:\n",
    "    i = json.load(file)\n",
    "\n",
    "f = i[\"images\"]\n",
    "\n",
    "for i in f:\n",
    "    shutil.copy(f\"{data_dir}/img/{i['file_name']}\", f\"{data_dir}train/\")\n",
    "\n",
    "\n",
    "# Val\n",
    "with open(coco_path_damage_val, \"r\") as file:\n",
    "    i = json.load(file)\n",
    "\n",
    "f = i[\"images\"]\n",
    "\n",
    "for i in f:\n",
    "    shutil.copy(f\"{data_dir}/img/{i['file_name']}\", f\"{data_dir}val/\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dl_model)",
   "language": "python",
   "name": "dl_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
